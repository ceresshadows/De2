{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd61cb78-6ef0-4f69-ab1b-a9ce4501149c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e5f2460-a942-4c13-bb7c-30b11446e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "\n",
    "### file path\n",
    "root_path = 'assets/case0-npc_cut_in/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31016486-6060-48d5-b7a8-f04110ced3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npc_from_txt(filepath):\n",
    "    f = open(filepath, 'r')\n",
    "    fframe = f.readlines()\n",
    "    \n",
    "    #append timestamp\n",
    "    df_ts = pd.DataFrame(columns=['npc_ts'])\n",
    "    #append npc\n",
    "    df_lc = pd.DataFrame(columns=['npc_x','npc_y','theta'])\n",
    "    \n",
    "    for row in fframe:\n",
    "        if row.find('timestamp_sec') != -1:\n",
    "            ts = re.findall(\"(?<=[AZaz])?[0-9.+-]+\",row) #exclude \"timestamp_sec:\"\n",
    "            ts = float(ts[0]) #convert to data format\n",
    "            l_no = fframe.index(row)\n",
    "            \n",
    "            lc_x = re.findall(\"(?<=[AZaz])?[0-9.+-]+\",fframe[l_no + 11])\n",
    "            lc_x = float(lc_x[0])\n",
    "            lc_y = re.findall(\"(?<=[AZaz])?[0-9.+-]+\",fframe[l_no + 12])\n",
    "            lc_y = float(lc_y[0])\n",
    "            theta = re.findall(\"(?<=[AZaz])?[0-9.+-]+\",fframe[l_no +15])\n",
    "            theta = float(theta[0])\n",
    "            \n",
    "            d_0 = {'npc_ts':[ts]}\n",
    "            d_df0 = pd.DataFrame(data=d_0)\n",
    "            df_ts = pd.concat([df_ts, d_df0])\n",
    "\n",
    "            d_1 = {'npc_x':[lc_x], 'npc_y':[lc_y],'theta':[theta]}\n",
    "            d_df1 = pd.DataFrame(data=d_1)\n",
    "            df_lc = pd.concat([df_lc, d_df1])\n",
    "    df = pd.concat([df_ts, df_lc], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def npc_from_txt_wid(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    blocks = re.split(r'module_name: \"perception_obstacle\"', content)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for block in blocks:\n",
    "        data = dict()\n",
    "        ts_match = re.search(r'timestamp_sec: ([\\d.+-]+)', block)\n",
    "        if ts_match:\n",
    "            ts = float(ts_match.group(1))   \n",
    "            data['npc_ts'] = ts\n",
    "        subblocks = re.split(r'perception_obstacle \\{', block)\n",
    "        for i, subblock in enumerate(subblocks):\n",
    "            id_match = re.search(r'id: (\\d+)', subblock)\n",
    "            x_match = re.search(r'position \\{\\s+x: ([\\d.+-]+)', subblock)\n",
    "            y_match = re.search(r'y: ([\\d.+-]+)', subblock)\n",
    "            theta_match = re.search(r'theta: ([\\d.+-]+)', subblock)\n",
    "            \n",
    "            if id_match and x_match and y_match and theta_match:\n",
    "                npc_id = int(id_match.group(1))\n",
    "                x = float(x_match.group(1))\n",
    "                y = float(y_match.group(1))\n",
    "                theta = float(theta_match.group(1))\n",
    "\n",
    "                data.update({\n",
    "                    f'NPC{npc_id}X': x,\n",
    "                    f'NPC{npc_id}Y': y,\n",
    "                    f'NPC{npc_id}Theta': theta,\n",
    "                })\n",
    "\n",
    "        if data:\n",
    "            df = pd.concat([df, pd.DataFrame([data])], ignore_index=True)\n",
    " \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb2adf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ego_from_txt(filepath):\n",
    "    f = open(filepath, 'r')\n",
    "    fframe = f.readlines()\n",
    "    \n",
    "    #append timestamp\n",
    "    df_ts = pd.DataFrame(columns=['ego_ts'])\n",
    "    #append position\n",
    "    df_lc = pd.DataFrame(columns=['egoX','egoY','heading'])\n",
    "    \n",
    "    for row in fframe:\n",
    "        if row.find('timestamp_sec') != -1:\n",
    "            ts = re.findall(\"(?<=[AZaz])?[0-9.+-]+\",row) #exclude \"timestamp_sec:\"\n",
    "            ts = float(ts[0]) #convert to data format\n",
    "            l_no = fframe.index(row)\n",
    "            \n",
    "            lc_x = re.findall(\"(?<=[AZaz])?[0-9.+-]+\",fframe[l_no + 6])\n",
    "            lc_x = float(lc_x[0])\n",
    "            lc_y = re.findall(\"(?<=[AZaz])?[0-9.+-]+\",fframe[l_no + 7])\n",
    "            lc_y = float(lc_y[0])\n",
    "            heading = re.findall(\"(?<=[AZaz])?[0-9.+-]+\",fframe[l_no +31])\n",
    "            heading = float(heading[0])\n",
    "            \n",
    "            d_0 = {'ego_ts':[ts]}\n",
    "            d_df0 = pd.DataFrame(data=d_0)\n",
    "            df_ts = pd.concat([df_ts, d_df0])\n",
    "\n",
    "            d_1 = {'egoX':[lc_x], 'egoY':[lc_y],'heading':[heading]}\n",
    "            d_df1 = pd.DataFrame(data=d_1)\n",
    "            df_lc = pd.concat([df_lc, d_df1])\n",
    "    df = pd.concat([df_ts, df_lc], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "437002f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmd_from_txt(filepath):\n",
    "    f = open(filepath, 'r')\n",
    "    fframe = f.readlines()\n",
    "    \n",
    "    # Initialize an empty DataFrame\n",
    "    df = pd.DataFrame(columns=['cmd_ts', 'throttle', 'brake', 'steering'])\n",
    "    \n",
    "    for l_no, row in enumerate(fframe):\n",
    "        if re.match(r'^header {', row):\n",
    "            ts = re.findall(\"(?<=[AZaz])?[0-9.+-]+\", fframe[l_no + 1])\n",
    "            ts = float(ts[0])\n",
    "\n",
    "            throttle = re.findall(\"(?<=[AZaz])?[0-9.+-]+\", fframe[l_no + 11])\n",
    "            if throttle:\n",
    "                throttle = float(throttle[0])\n",
    "            else:\n",
    "                throttle = re.findall(\"(?<=[AZaz])?[0-9.+-]+\", fframe[l_no + 12])\n",
    "                if throttle:\n",
    "                    throttle = float(throttle[0])\n",
    "                else:\n",
    "                    print(f\"Error in {filepath}, line {l_no}: Throttle value not found\")\n",
    "                    print(f\"timestamp = {ts}\")\n",
    "\n",
    "            brake = re.findall(\"(?<=[AZaz])?[0-9.+-]+\", fframe[l_no + 12])\n",
    "            brake = float(brake[0])\n",
    "\n",
    "            steering = re.findall(\"(?<=[AZaz])?[0-9.+-]+\", fframe[l_no + 14])\n",
    "            steering = float(steering[0])\n",
    "\n",
    "            col_df = pd.concat([pd.DataFrame({'cmd_ts': [ts]}), \n",
    "                                 pd.DataFrame({'throttle': [throttle]}), \n",
    "                                 pd.DataFrame({'brake': [brake]}), \n",
    "                                 pd.DataFrame({'steering': [steering]})], axis=1)\n",
    "            \n",
    "            df = pd.concat([df, col_df], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5abb13d4-7044-416d-bc99-40cbe1866180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_and_average(serial):\n",
    "    data_path = root_path\n",
    "    df_npc = npc_from_txt_wid(data_path+f'txt_record/{serial}_obstacle.txt')\n",
    "    df_ego = ego_from_txt(data_path+    f'txt_record/{serial}_pose.txt')\n",
    "    df_cmd = cmd_from_txt(data_path+    f'txt_record/{serial}_control.txt')\n",
    "\n",
    "    delta_ts = df_ego['ego_ts'].iloc[0] - df_npc['npc_ts'].iloc[0]\n",
    "    df_npc['npc_ts'] += delta_ts\n",
    "\n",
    "    aligned_ego_list = []\n",
    "    avg_cmd_list = []\n",
    "    aligned_npc_list = []\n",
    "    \n",
    "    last_npc_idx = 0\n",
    "    \n",
    "    for i in range(df_npc.shape[0]):\n",
    "        ego_indices = np.where(df_ego['ego_ts'] < df_npc['npc_ts'].iloc[i])[0]\n",
    "        if ego_indices.size == 0:\n",
    "            continue\n",
    "        ego_idx = ego_indices[-1]\n",
    "        \n",
    "        cmd_indices = np.where((df_cmd['cmd_ts'] >= df_npc['npc_ts'].iloc[last_npc_idx]) & \n",
    "                               (df_cmd['cmd_ts'] < df_npc['npc_ts'].iloc[i]))[0]\n",
    "\n",
    "        if cmd_indices.size > 0:\n",
    "            aligned_ego_list.append(df_ego.iloc[ego_idx])\n",
    "            avg_cmd_list.append(df_cmd.iloc[cmd_indices].mean())\n",
    "            aligned_npc_list.append(df_npc.iloc[i])\n",
    "        \n",
    "        last_npc_idx = i\n",
    "\n",
    "    df_aligned_ego = pd.DataFrame(aligned_ego_list).reset_index(drop=True)\n",
    "    df_avg_cmd = pd.DataFrame(avg_cmd_list).reset_index(drop=True)\n",
    "    df_aligned_npc = pd.DataFrame(aligned_npc_list).reset_index(drop=True)\n",
    "\n",
    "    return df_aligned_ego, df_aligned_npc, df_avg_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "616cbfdd-7aba-482e-9cbc-6dd3f3d2b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment for testing\n",
    "# aligned_ego, aligned_npc, avg_cmd = align_and_average(16)\n",
    "\n",
    "# # convert numpy to pandas DataFrame\n",
    "# df_ego = pd.DataFrame(aligned_ego) \n",
    "# df_cmd = pd.DataFrame(avg_cmd)     \n",
    "# df_npc = pd.DataFrame(aligned_npc)        \n",
    "\n",
    "# # save as csv file\n",
    "# df_ego.to_csv(root_path+'aligned_ego.csv', index=False)\n",
    "# df_cmd.to_csv(root_path+'avg_cmd.csv', index=False)\n",
    "# df_npc.to_csv(root_path+'aligned_npc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "674bc411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_serials(serials):\n",
    "    merge_df = pd.DataFrame()\n",
    "    \n",
    "    for i in range(serials):\n",
    "        print(f\"Processing serial {i}\")\n",
    "        aligned_ego, aligned_npc, avg_cmd = align_and_average(i)\n",
    "        tmp = aligned_ego['ego_ts'].to_frame(name='time')\n",
    "        tmp['id'] = i + 1  \n",
    "        tmp = pd.concat([tmp, aligned_ego, aligned_npc, avg_cmd], axis=1)\n",
    "        \n",
    "        columns_to_drop = ['ego_ts', 'cmd_ts', 'npc_ts']\n",
    "        for col in columns_to_drop:\n",
    "            if col not in tmp.columns:\n",
    "                print(f\"Warning: Column '{col}' not found in DataFrame at iteration {i}. Available columns: {tmp.columns}\")\n",
    "            else:\n",
    "                tmp = tmp.drop(columns=col)\n",
    "        merge_df = pd.concat([merge_df, tmp], ignore_index=True)\n",
    "    return merge_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f1da9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract static feature\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def parse_simulation_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    data = []\n",
    "    iteration_data = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        if \"Iteration\" in line:\n",
    "            if iteration_data:\n",
    "                data.append(iteration_data)\n",
    "                iteration_data = {}\n",
    "            iteration_data['id'] = int(re.search(r'\\d+', line).group())\n",
    "        elif \"Weather\" in line:\n",
    "            weather_data = re.findall(r'(\\w+)=([\\d.]+)', line)\n",
    "            for item in weather_data:\n",
    "                iteration_data[item[0]] = float(item[1])\n",
    "        elif \"Time of day\" in line:\n",
    "            iteration_data['daytime'] = float(re.search(r'[\\d.]+', line).group())\n",
    "        elif \"Collision\" in line:\n",
    "            match = re.search(r\"Collision: (True|False)\", line)\n",
    "            if match:\n",
    "                value = match.group(1)\n",
    "                iteration_data['result'] = 1 if value == \"True\" else 0\n",
    "    \n",
    "    if iteration_data:\n",
    "        data.append(iteration_data)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "file_path = root_path+'simulation_data.txt'\n",
    "df = parse_simulation_data(file_path)\n",
    "\n",
    "# # uncomment for testing\n",
    "# print(df)\n",
    "df.to_csv(root_path+'features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b618be6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing serial 0\n",
      "Processing serial 1\n",
      "Processing serial 2\n",
      "Processing serial 3\n",
      "Processing serial 4\n",
      "Processing serial 5\n",
      "Processing serial 6\n",
      "Processing serial 7\n",
      "Processing serial 8\n",
      "Processing serial 9\n",
      "Processing serial 10\n",
      "Processing serial 11\n",
      "Processing serial 12\n",
      "Processing serial 13\n",
      "Processing serial 14\n",
      "Processing serial 15\n",
      "Processing serial 16\n",
      "Processing serial 17\n",
      "Processing serial 18\n",
      "Processing serial 19\n",
      "Processing serial 20\n",
      "Processing serial 21\n",
      "Processing serial 22\n",
      "Processing serial 23\n",
      "Processing serial 24\n",
      "Processing serial 25\n",
      "Processing serial 26\n",
      "Processing serial 27\n",
      "Processing serial 28\n",
      "Processing serial 29\n",
      "Processing serial 30\n"
     ]
    }
   ],
   "source": [
    "### edit # serials to proceed\n",
    "df_merge = pd.DataFrame()\n",
    "df_merge = process_serials(31)\n",
    "df_merge = df_merge.reindex(columns=['id', 'time'] + [col for col in df_merge.columns if col not in ['id', 'time']])\n",
    "df_merge.insert(0, \"\", range(1, len(df_merge) + 1))\n",
    "df_merge.to_csv(root_path+'data_processed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da28629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perpendicular_distance(x, y, line):\n",
    "    x, y = float(x), float(y)  # Convert x and y to float\n",
    "    min_distance = float('inf')\n",
    "    sign = 1  # Positive for left, negative for right\n",
    "    \n",
    "    for i in range(len(line) - 1):\n",
    "        x1, y1 = float(line[i]['x']), float(line[i]['y'])  # Convert string to float\n",
    "        x2, y2 = float(line[i+1]['x']), float(line[i+1]['y'])  # Convert string to float\n",
    "        \n",
    "        v_length = math.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "        dot_product = ((x-x1)*(x2-x1) + (y-y1)*(y2-y1)) / v_length\n",
    "        \n",
    "        if dot_product < 0:\n",
    "            distance = math.sqrt((x-x1)**2 + (y-y1)**2)\n",
    "        elif dot_product > v_length:\n",
    "            distance = math.sqrt((x-x2)**2 + (y-y2)**2)\n",
    "        else:\n",
    "            # Compute the cross product to determine the side\n",
    "            cross_product = (x - x1) * (y2 - y1) - (y - y1) * (x2 - x1)\n",
    "            if cross_product < 0:\n",
    "                sign = -1\n",
    "            distance = abs((y2-y1)*x - (x2-x1)*y + x2*y1 - y2*x1) / v_length\n",
    "        \n",
    "        # Update the minimum distance with the correct sign\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance * sign\n",
    "            \n",
    "    return min_distance\n",
    "\n",
    "\n",
    "def find_lane_and_distance(x, y, lanes):\n",
    "    if x and y:\n",
    "        x, y = float(x), float(y)  # Convert x and y to float\n",
    "    else:\n",
    "        return None, None\n",
    "    min_distance = float('inf')\n",
    "    closest_lane_id = None\n",
    "    \n",
    "    for lane_id, lane_data in lanes.items():\n",
    "        central_curve = lane_data['central_curve']\n",
    "        distance = compute_perpendicular_distance(x, y, central_curve)\n",
    "        \n",
    "        if abs(distance) < abs(min_distance):\n",
    "            min_distance = distance\n",
    "            closest_lane_id = lane_id\n",
    "          \n",
    "    # If the nearest lane distance is less than 2m, return that lane and distance, otherwise return None\n",
    "    if abs(min_distance) < 2:\n",
    "        lane_number = re.findall(r'\\d+', closest_lane_id)\n",
    "        return lane_number[0] if lane_number else closest_lane_id, min_distance\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "# # uncomment for testing\n",
    "# with open('assets/lane_info.json', 'r') as f:\n",
    "#      lanes = json.load(f)\n",
    "# x, y = 592418.56176757812, 4134988.5171813965  # Example point\n",
    "# lane_id, distance = find_lane_and_distance(x, y, lanes)\n",
    "\n",
    "# if lane_id:\n",
    "#     print(f\"The point ({x}, {y}) is on lane {lane_id} with a distance of {distance} to the central curve.\")\n",
    "# else:\n",
    "#     print(lane_id, distance)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(root_path+'data_processed.csv')\n",
    "# Load lanes data from JSON\n",
    "with open('assets/lane_info.json', 'r') as f:\n",
    "    lanes = json.load(f)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    lane_id, distance = find_lane_and_distance(row['egoX'], row['egoY'],lanes)\n",
    "    df.at[index, 'egoLane'] = lane_id\n",
    "    df.at[index, 'egoLaneOffset'] = distance\n",
    "    \n",
    "    lane_id, distance = find_lane_and_distance(row['NPC1X'], row['NPC1Y'],lanes)\n",
    "    df.at[index, 'NPC1Lane'] = lane_id\n",
    "    df.at[index, 'NPC1LaneOffset'] = distance\n",
    "\n",
    "    # lane_id, distance = find_lane_and_distance(row['NPC2X'], row['NPC2Y'],lanes)\n",
    "    # df.at[index, 'NPC2Lane'] = lane_id\n",
    "    # df.at[index, 'NPC2LaneOffset'] = distance\n",
    "\n",
    "df.to_csv(root_path+'data_processed.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
